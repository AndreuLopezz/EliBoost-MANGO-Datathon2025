{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d57472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\t\n",
    "df = pd.read_csv(\"../mango/train.csv\", sep=\";\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def combine_attributes_jerarquica(row):\n",
    "    \"\"\"\n",
    "    Combina atributos textuales en formato jer√°rquico\n",
    "    M√°xima relevancia: categor√≠a/arquetipo ‚Üí atributos f√≠sicos ‚Üí contexto\n",
    "    \"\"\"\n",
    "    # Definir columnas por nivel de importancia (excluyendo num√©ricas)\n",
    "    texto_cols = [\n",
    "        'aggregated_family', 'family', 'category',\n",
    "        'fabric', 'color_name',\n",
    "        'length_type', 'silhouette_type', 'waist_type',\n",
    "        'neck_lapel_type', 'sleeve_length_type', \n",
    "        'heel_shape_type', 'toecap_type',\n",
    "        'woven_structure', 'knit_structure',\n",
    "        'print_type', 'archetype', 'moment'\n",
    "    ]\n",
    "    \n",
    "    # Extraer valores no nulos\n",
    "    valores = []\n",
    "    for col in texto_cols:\n",
    "        val = row[col]\n",
    "        # Ignorar NaN, None, y strings vac√≠os\n",
    "        if pd.notna(val) and str(val).strip():\n",
    "            valores.append(str(val).strip())\n",
    "    valores.append(f'has plus sizes {row[\"has_plus_sizes\"]}')\n",
    "    # Unir con separadores claros\n",
    "    return ' , '.join(valores)  # Usa ' | ' para separaci√≥n visual clara\n",
    "\n",
    "\n",
    "# Cargar datos (ajusta separador si es necesario)\n",
    "\n",
    "# ELEGIR UNA ESTRATEGIA\n",
    "# Para producci√≥n general: usa la jer√°rquica\n",
    "df['combined_text'] = df.apply(combine_attributes_jerarquica, axis=1)\n",
    "\n",
    "# Ver ejemplo\n",
    "print(\"Ejemplo combinado:\\n\", df['combined_text'].iloc[0])\n",
    "\n",
    "# Generar embeddings\n",
    "embeddings = model.encode(\n",
    "    df['combined_text'].tolist(),\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True  # Para ver el progreso\n",
    ")\n",
    "\n",
    "print(f\"\\nEmbeddings generados: {embeddings.shape}\")\n",
    "\n",
    "# Guardar\n",
    "torch.save(embeddings, 'embeddings_prendas.pt')\n",
    "df[['ID', 'combined_text']].to_csv('textos_combinados.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3506b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_tensor = torch.load('embeddings_prendas.pt')\n",
    "print(f\"‚úì Embeddings cargados: {embeddings_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f0796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# ============================================\n",
    "# 1. CARGAR LOS ARCHIVOS QUE YA TIENES\n",
    "# ============================================\n",
    "\n",
    "\n",
    "# Cargar tensor de embeddings (lo que guardaste con torch.save)\n",
    "\n",
    "\n",
    "# Cargar DataFrame original (tu CSV completo)\n",
    "df_original = pd.read_csv('../mango/train.csv', sep=';')\n",
    "print(f\"‚úì DataFrame original: {df_original.shape}\")\n",
    "\n",
    "# Cargar referencia de IDs (opcional pero recomendado para verificar)\n",
    "df_textos = pd.read_csv('textos_combinados.csv')\n",
    "print(f\"‚úì DataFrame de referencia: {df_textos.shape}\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 2. CREAR DataFrame con embeddings e IDs\n",
    "# ============================================\n",
    "\n",
    "# Convertir tensor a lista de listas (cada embedding es una lista)\n",
    "embeddings_lista = embeddings_tensor.cpu().numpy().tolist()\n",
    "\n",
    "# Crear DataFrame temporal con ID y embedding\n",
    "embeddings_df = pd.DataFrame({\n",
    "    'ID': df_textos['ID'],  # Usamos los IDs del archivo de referencia\n",
    "    'embedding_tabla': embeddings_lista\n",
    "})\n",
    "\n",
    "print(f\"\\n‚úì DataFrame de embeddings creado: {embeddings_df.shape}\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 3. FUSIONAR CON EL DATAFRAME ORIGINAL (MERGE POR ID)\n",
    "# ============================================\n",
    "\n",
    "# Esto es lo M√ÅS IMPORTANTE: merge por ID asegura alineaci√≥n perfecta\n",
    "df_final = df_original.merge(embeddings_df, on='ID', how='left')\n",
    "\n",
    "# Verificar que la fusi√≥n fue exitosa\n",
    "num_sin_embedding = df_final['embedding_tabla'].isna().sum()\n",
    "if num_sin_embedding > 0:\n",
    "    print(f\"‚ö†Ô∏è ALERTA: {num_sin_embedding} prendas no tienen embedding\")\n",
    "    print(\"IDs sin embedding:\", df_final[df_final['embedding_tabla'].isna()]['ID'].tolist())\n",
    "else:\n",
    "    print(\"\\n‚úÖ Fusi√≥n exitosa: todos los embeddings se unieron correctamente\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 4. VERIFICAR INTEGRIDAD\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüîç Verificaci√≥n final:\")\n",
    "print(f\"   - Filas en DataFrame final: {len(df_final):,}\")\n",
    "print(f\"   - Columnas nuevas: {len(df_original.columns)} originales + 1 (embedding) = {len(df_final.columns)}\")\n",
    "print(f\"   - Tama√±o del embedding: {len(df_final.iloc[0]['embedding_tabla'])} dimensiones\")\n",
    "print(f\"   - Tipo de dato: {type(df_final.iloc[0]['embedding_tabla'])}\")\n",
    "\n",
    "# Verificar que el embedding es v√°lido (norma L2 ‚âà 1.0)\n",
    "primer_embedding = torch.tensor(df_final.iloc[0]['embedding_tabla'])\n",
    "norma = torch.norm(primer_embedding).item()\n",
    "print(f\"   - Norma L2 del primer embedding: {norma:.6f} (debe ser ‚âà 1.0)\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 5. GUARDAR RESULTADO FINAL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüíæ Guardando archivo final...\")\n",
    "\n",
    "# OPCI√ìN A: Pickle (recomendada - preserva objetos Python)\n",
    "df_final.to_pickle('prendas_con_embeddings_final.pkl')\n",
    "print(\"   ‚úì Guardado como 'prendas_con_embeddings_final.pkl'\")\n",
    "\n",
    "# OPCI√ìN B: Parquet (m√°s eficiente, compatible con Big Data)\n",
    "df_final.to_parquet('prendas_con_embeddings_final.parquet', index=False)\n",
    "print(\"   ‚úì Guardado como 'prendas_con_embeddings_final.parquet'\")\n",
    "\n",
    "# OPCI√ìN C: CSV (solo si necesitas abrirlo en Excel - tama√±o muy grande)\n",
    "# df_final.to_csv('prendas_con_embeddings_final.csv', index=False, sep=';')\n",
    "# print(\"   ‚úì Guardado como 'prendas_con_embeddings_final.csv'\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 6. EJEMPLO DE USO DEL DATAFRAME FINAL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüéØ Ejemplo de acceso a embeddings:\")\n",
    "\n",
    "# Acceder al embedding de una prenda espec√≠fica\n",
    "id_ejemplo = df_final.iloc[0]['ID']\n",
    "embedding_ejemplo = df_final[df_final['ID'] == id_ejemplo]['embedding_tabla'].iloc[0]\n",
    "\n",
    "print(f\"   Prenda ID: {id_ejemplo}\")\n",
    "print(f\"   Categor√≠a: {df_final[df_final['ID'] == id_ejemplo]['category'].iloc[0]}\")\n",
    "print(f\"   Color: {df_final[df_final['ID'] == id_ejemplo]['color_name'].iloc[0]}\")\n",
    "print(f\"   Embedding (primeros 5 valores): {embedding_ejemplo[:5]}\")\n",
    "\n",
    "print(\"\\n‚ú® ¬°Proceso completado! Tu DataFrame ahora tiene todas las columnas originales + embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b47c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['embedding_tabla']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
